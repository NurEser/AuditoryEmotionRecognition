{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common_Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@author: Jiaxin Ye\n",
    "@contact: jiaxin-ye@foxmail.com\n",
    "\"\"\"\n",
    "# -*- coding:UTF-8 -*-\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "#from Model import TIMNET_Model\n",
    "import argparse\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@author: Jiaxin Ye\n",
    "@contact: jiaxin-ye@foxmail.com\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "\n",
    "class Common_Model(object):\n",
    "\n",
    "    def __init__(self, save_path: str = '', name: str = 'Not Specified'):\n",
    "        self.model = None\n",
    "        self.trained = False \n",
    "\n",
    "    def train(self, x_train, y_train, x_val, y_val):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def predict(self, samples):\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "\n",
    "    def predict_proba(self, samples):\n",
    "        if not self.trained:\n",
    "            sys.stderr.write(\"No Model.\")\n",
    "            sys.exit(-1)\n",
    "        return self.model.predict_proba(samples)\n",
    "\n",
    "    def save_model(self, model_name: str):\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@author: Jiaxin Ye\n",
    "@contact: jiaxin-ye@foxmail.com\n",
    "\"\"\"\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.layers import Activation, Lambda\n",
    "from tensorflow.keras.layers import Conv1D, SpatialDropout1D,add,GlobalAveragePooling1D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.activations import sigmoid\n",
    "\n",
    "def Temporal_Aware_Block(x, s, i, activation, nb_filters, kernel_size, dropout_rate=0, name=''):\n",
    "\n",
    "    original_x = x\n",
    "    #1.1\n",
    "    conv_1_1 = Conv1D(filters=nb_filters, kernel_size=kernel_size,\n",
    "                  dilation_rate=i, padding='causal')(x)\n",
    "    conv_1_1 = BatchNormalization(trainable=True,axis=-1)(conv_1_1)\n",
    "    conv_1_1 =  Activation(activation)(conv_1_1)\n",
    "    output_1_1 =  SpatialDropout1D(dropout_rate)(conv_1_1)\n",
    "    # 2.1\n",
    "    conv_2_1 = Conv1D(filters=nb_filters, kernel_size=kernel_size,\n",
    "                  dilation_rate=i, padding='causal')(output_1_1)\n",
    "    conv_2_1 = BatchNormalization(trainable=True,axis=-1)(conv_2_1)\n",
    "    conv_2_1 = Activation(activation)(conv_2_1)\n",
    "    output_2_1 =  SpatialDropout1D(dropout_rate)(conv_2_1)\n",
    "    \n",
    "    if original_x.shape[-1] != output_2_1.shape[-1]:\n",
    "        original_x = Conv1D(filters=nb_filters, kernel_size=1, padding='same')(original_x)\n",
    "        \n",
    "    output_2_1 = Lambda(sigmoid)(output_2_1)\n",
    "    F_x = Lambda(lambda x: tf.multiply(x[0], x[1]))([original_x, output_2_1])\n",
    "    return F_x\n",
    "\n",
    "\n",
    "class TIMNET:\n",
    "    def __init__(self,\n",
    "                 nb_filters=64,\n",
    "                 kernel_size=2,\n",
    "                 nb_stacks=1,\n",
    "                 dilations=None,\n",
    "                 activation = \"relu\",\n",
    "                 dropout_rate=0.1,\n",
    "                 return_sequences=True,\n",
    "                 name='TIMNET'):\n",
    "        self.name = name\n",
    "        self.return_sequences = return_sequences\n",
    "        self.activation = activation\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.dilations = dilations\n",
    "        self.nb_stacks = nb_stacks\n",
    "        self.kernel_size = kernel_size\n",
    "        self.nb_filters = nb_filters\n",
    "\n",
    "        self.supports_masking = True\n",
    "        self.mask_value=0.\n",
    "\n",
    "        if not isinstance(nb_filters, int):\n",
    "            raise Exception()\n",
    "\n",
    "    def __call__(self, inputs, mask=None):\n",
    "        if self.dilations is None:\n",
    "            self.dilations = 8\n",
    "        forward = inputs\n",
    "        backward = K.reverse(inputs,axes=1)\n",
    "        \n",
    "        print(\"Input Shape=\",inputs.shape)\n",
    "        forward_convd = Conv1D(filters=self.nb_filters,kernel_size=1, dilation_rate=1, padding='causal')(forward)\n",
    "        backward_convd = Conv1D(filters=self.nb_filters,kernel_size=1, dilation_rate=1, padding='causal')(backward)\n",
    "        \n",
    "        final_skip_connection = []\n",
    "        \n",
    "        skip_out_forward = forward_convd\n",
    "        skip_out_backward = backward_convd\n",
    "        \n",
    "        for s in range(self.nb_stacks):\n",
    "            for i in [2 ** i for i in range(self.dilations)]:\n",
    "                skip_out_forward = Temporal_Aware_Block(skip_out_forward, s, i, self.activation,\n",
    "                                                        self.nb_filters,\n",
    "                                                        self.kernel_size, \n",
    "                                                        self.dropout_rate,  \n",
    "                                                        name=self.name)\n",
    "                skip_out_backward = Temporal_Aware_Block(skip_out_backward, s, i, self.activation,\n",
    "                                                        self.nb_filters,\n",
    "                                                        self.kernel_size, \n",
    "                                                        self.dropout_rate,  \n",
    "                                                        name=self.name)\n",
    "                \n",
    "                temp_skip = add([skip_out_forward, skip_out_backward],name = \"biadd_\"+str(i))\n",
    "                temp_skip=GlobalAveragePooling1D()(temp_skip)\n",
    "                temp_skip=tf.expand_dims(temp_skip, axis=1)\n",
    "                final_skip_connection.append(temp_skip)\n",
    "\n",
    "        output_2 = final_skip_connection[0]\n",
    "        for i,item in enumerate(final_skip_connection):\n",
    "            if i==0:\n",
    "                continue\n",
    "            output_2 = K.concatenate([output_2,item],axis=-2)\n",
    "        x = output_2\n",
    "\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TIMNET_MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@author: Jiaxin Ye\n",
    "@contact: jiaxin-ye@foxmail.com\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import tensorflow.keras.backend as K\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import SGD,Adam\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras.layers import Layer,Dense,Input\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#from Common_Model import Common_Model\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "#from TIMNET import TIMNET\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def smooth_labels(labels, factor=0.1):\n",
    "    # smooth the labels\n",
    "    labels *= (1 - factor)\n",
    "    labels += (factor / labels.shape[1])\n",
    "    return labels\n",
    "\n",
    "class WeightLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(WeightLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(name='kernel',\n",
    "                                      shape=(input_shape[1],1),\n",
    "                                      initializer='uniform',\n",
    "                                      trainable=True)  \n",
    "        super(WeightLayer, self).build(input_shape)  \n",
    " \n",
    "    def call(self, x):\n",
    "        tempx = tf.transpose(x,[0,2,1])\n",
    "        x = K.dot(tempx,self.kernel)\n",
    "        x = tf.squeeze(x,axis=-1)\n",
    "        return  x\n",
    " \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0],input_shape[2])\n",
    "    \n",
    "def softmax(x, axis=-1):\n",
    "    ex = K.exp(x - K.max(x, axis=axis, keepdims=True))\n",
    "    returnval = ex/K.sum(ex, axis=axis, keepdims=True)\n",
    "    print(\"returnval is: \")\n",
    "    print(returnval)\n",
    "    return ex/K.sum(ex, axis=axis, keepdims=True)\n",
    "\n",
    "class TIMNET_Model(Common_Model):\n",
    "    def __init__(self, args, input_shape, class_label, **params):\n",
    "        super(TIMNET_Model,self).__init__(**params)\n",
    "        self.args = args\n",
    "        self.data_shape = input_shape\n",
    "        self.num_classes = len(class_label)\n",
    "        self.class_label = class_label\n",
    "        self.matrix = []\n",
    "        self.eva_matrix = []\n",
    "        self.acc = 0\n",
    "        print(\"TIMNET MODEL SHAPE:\",input_shape)\n",
    "    \n",
    "    def create_model(self):\n",
    "        self.inputs=Input(shape = (self.data_shape[0],self.data_shape[1]))\n",
    "        print(self.inputs.shape)\n",
    "        self.multi_decision = TIMNET(nb_filters=self.args.filter_size,\n",
    "                                kernel_size=self.args.kernel_size, \n",
    "                                nb_stacks=self.args.stack_size,\n",
    "                                dilations=self.args.dilation_size,\n",
    "                                dropout_rate=self.args.dropout,\n",
    "                                activation = self.args.activation,\n",
    "                                return_sequences=True, \n",
    "                                name='TIMNET')(self.inputs)\n",
    "        \n",
    "        #self.time_probs= TimeDistributed(Dense(self.num_classes, activation='softmax'))(self.multi_decision)\n",
    "        self.decision = WeightLayer()(self.multi_decision)\n",
    "        \n",
    "        #self.time_probs= TimeDistributed(Dense(self.num_classes, activation='softmax'))(self.decision)\n",
    "        self.predictions = Dense(self.num_classes, activation='softmax')(self.decision)\n",
    "        self.model = Model(inputs = self.inputs, outputs = [ self.predictions])\n",
    "        \n",
    "        self.model.compile(loss = \"categorical_crossentropy\",\n",
    "                           optimizer =Adam(learning_rate=self.args.lr, beta_1=self.args.beta1, beta_2=self.args.beta2, epsilon=1e-8),\n",
    "                           metrics = ['accuracy'])\n",
    "        print(\"Temporal create succes!\")\n",
    "        \n",
    "   \n",
    "   \n",
    "    def test_one_sample(self, sample , framebyframe):\n",
    "        # if audio is split to frames framebyframe must be True. \n",
    "        predictions = []\n",
    "        self.create_model()\n",
    "        path ='./Test_Models/RAVDE_46'\n",
    "        weight_path= path+'/'+str(self.args.split_fold)+\"-fold_weights_best_\"+str(2)+\".hdf5\"\n",
    "        self.model.load_weights(weight_path)\n",
    "        if framebyframe:\n",
    "            y_pred_best = self.model.predict(sample)  \n",
    "            transposed_probabilities = np.transpose(y_pred_best)\n",
    "            #for printing out each emotion probability graph seperately\n",
    "            n_classes = len(self.class_label)\n",
    "            fig, axes = plt.subplots(3, 3, figsize=(6, 6))  \n",
    "            axes = axes.flatten()\n",
    "            plt.suptitle(\"Emotion Probabilities\")\n",
    "            plt.xlabel('Samples')\n",
    "            plt.ylabel('Probability')\n",
    "            for i, class_name in enumerate(self.class_label):\n",
    "                m = i % 3\n",
    "                n = i / 3\n",
    "                axes[i].plot(transposed_probabilities[i], label=class_name)\n",
    "                axes[i].set_title(class_name)\n",
    "                axes[i].set_ylim(0, 1)\n",
    "                #axes[i].legend(False)\n",
    "            plt.tight_layout() \n",
    "            plt.show()\n",
    "\n",
    "            #for printing out emotions together. \n",
    "            colors = [\"r\", \"c\", \"g\", \"y\", \"m\", \"b\", \"k\", \"orange\"] \n",
    "            plt.figure(figsize=(30,20))\n",
    "            n=100\n",
    "            for i, class_name in enumerate(self.class_label):\n",
    "                plt.plot(np.arange(y_pred_best.shape[0]), transposed_probabilities[i], label=class_name, color=colors[i])\n",
    "                #plt.plot(np.arange(0, y_pred_best.shape[0], n), transposed_probabilities[i][::n], label=class_name, color=colors[i])\n",
    "\n",
    "            plt.xlabel('Sample index')\n",
    "            plt.ylabel('Probabilities')\n",
    "            plt.legend() \n",
    "            plt.title('Emotion Probabilities for Each Class')\n",
    "            plt.show()\n",
    "\n",
    "        else: \n",
    "            y_pred_best = self.model.predict(np.expand_dims(sample, 0))\n",
    "            print(\"y_predictions are: \")\n",
    "            print(y_pred_best)\n",
    "        \n",
    "        \n",
    "        return y_pred_best  \n",
    "    \n",
    "    def test_two_samples(self, sample1, sample2):\n",
    "        self.create_model()\n",
    "        path ='./Test_Models/RAVDE_46'\n",
    "        weight_path = path+'/'+str(self.args.split_fold)+\"-fold_weights_best_\"+str(4)+\".hdf5\"\n",
    "        self.model.load_weights(weight_path)\n",
    "\n",
    "        y_pred_best1 = self.model.predict(sample1)  \n",
    "        y_pred_best2 = self.model.predict(sample2)\n",
    "    \n",
    "        transposed_probabilities1 = np.transpose(y_pred_best1)\n",
    "        transposed_probabilities2 = np.transpose(y_pred_best2)\n",
    "    \n",
    "        colors = [\"r\", \"c\", \"g\", \"y\", \"m\", \"b\", \"k\", \"orange\"]\n",
    "        marker = ['s', '^']  # 's' for square, '^' for triangle\n",
    "        lines = []\n",
    "        labels = []\n",
    "\n",
    "        plt.figure(figsize=(20,12))\n",
    "        for i, class_name in enumerate(self.class_label):\n",
    "            line1, = plt.plot(np.arange(y_pred_best1.shape[0]), transposed_probabilities1[i], label=class_name, color=colors[i], marker=marker[0])\n",
    "            #line2, = plt.plot(np.arange(y_pred_best2.shape[0]), transposed_probabilities2[i], label=class_name, color=colors[i], marker=marker[1])    \n",
    "            line2, = plt.plot(np.arange(1, y_pred_best2.shape[0]+1), transposed_probabilities2[i], label=class_name, color=colors[i], marker=marker[1])  # Adjusted for speaker2\n",
    "\n",
    "            if i == 0:  \n",
    "                lines.append(line1)\n",
    "                lines.append(line2)\n",
    "                labels.append('Speaker1')\n",
    "                labels.append('Speaker2')\n",
    "\n",
    "        plt.xlabel('Sample index')\n",
    "        plt.ylabel('Probabilities')\n",
    "\n",
    "        leg1 = plt.legend(lines, labels, title='Speakers', loc='upper left')\n",
    "\n",
    "        emotions = [plt.Line2D([0], [0], color=c, lw=4) for c in colors]\n",
    "        leg2 = plt.legend(emotions, self.class_label, title='Emotions', loc='lower left')\n",
    "\n",
    "        plt.gca().add_artist(leg1)  \n",
    "        plt.title('Emotion Probabilities for Each Class')\n",
    "        plt.show()\n",
    "\n",
    "    \n",
    " \n",
    "    def test_original(self, x, y, path, fold):\n",
    "        i=1\n",
    "        kfold = KFold(n_splits=self.args.split_fold, shuffle=True, random_state=self.args.random_seed)\n",
    "        avg_accuracy = 0\n",
    "        avg_loss = 0\n",
    "        x_feats = []\n",
    "        y_labels = []\n",
    "        for train, test in kfold.split(x, y):\n",
    "            self.create_model()\n",
    "            weight_path=path+'/'+str(self.args.split_fold)+\"-fold_weights_best_\"+str(i)+\".hdf5\"\n",
    "            self.model.fit(x[train], y[train],validation_data=(x[test],  y[test]),batch_size = 64,epochs = 0,verbose=0)\n",
    "            self.model.load_weights(weight_path)#+source_name+'_single_best.hdf5')\n",
    "            best_eva_list = self.model.evaluate(x[test],  y[test])\n",
    "        \n",
    "            avg_loss += best_eva_list[0]\n",
    "            avg_accuracy += best_eva_list[1]\n",
    "            print(str(i)+'_Model evaluation: ', best_eva_list,\"   Now ACC:\",str(round(avg_accuracy*10000)/100/i))\n",
    "            i+=1\n",
    "            y_pred_best = self.model.predict(x[test]) \n",
    "        \n",
    "            transposed_probabilities = np.transpose(y_pred_best)\n",
    "            \n",
    "            self.matrix.append(confusion_matrix(np.argmax(y[test],axis=1),np.argmax(y_pred_best,axis=1)))\n",
    "            em = classification_report(np.argmax(y[test],axis=1),np.argmax(y_pred_best,axis=1), target_names=self.class_label,output_dict=True)\n",
    "            self.eva_matrix.append(em)\n",
    "            print(classification_report(np.argmax(y[test],axis=1),np.argmax(y_pred_best,axis=1), target_names=self.class_label))\n",
    "            caps_layer_model = Model(inputs=self.model.input,\n",
    "            outputs=self.model.get_layer(index=-2).output)\n",
    "            feature_source = caps_layer_model.predict(x[test])\n",
    "            x_feats.append(feature_source)\n",
    "            y_labels.append(y[test])\n",
    "            \n",
    "        print(\"Average ACC:\",avg_accuracy/self.args.split_fold)\n",
    "        self.acc = avg_accuracy/self.args.split_fold\n",
    "        \n",
    "        return x_feats, y_labels\n",
    "\n",
    "\n",
    "\n",
    "    def test(self, x, y, path):\n",
    "        i=1\n",
    "        kfold = KFold(n_splits=self.args.split_fold, shuffle=True, random_state=self.args.random_seed)\n",
    "        avg_accuracy = 0\n",
    "        avg_loss = 0\n",
    "        x_feats = []\n",
    "        y_labels = []\n",
    "        for train, test in kfold.split(x, y):\n",
    "            self.create_model()\n",
    "            weight_path=path+'/'+str(self.args.split_fold)+\"-fold_weights_best_\"+str(i)+\".hdf5\"\n",
    "            self.model.fit(x[train], y[train],validation_data=(x[test][0],  y[test][0]),batch_size = 64,epochs = 0,verbose=0)\n",
    "            self.model.load_weights(weight_path)#+source_name+'_single_best.hdf5')\n",
    "            best_eva_list = self.model.evaluate(np.expand_dims(x[test][0], 0), np.expand_dims(y[test][0], 0))\n",
    "            #best_eva_list = self.model.evaluate(x[test][0],  y[test][0])\n",
    "            x_test = x[test]\n",
    "            x_test0 = x_test[0]\n",
    "            avg_loss += best_eva_list[0]\n",
    "            avg_accuracy += best_eva_list[1]\n",
    "            print(str(i)+'_Model evaluation: ', best_eva_list,\"   Now ACC:\",str(round(avg_accuracy*10000)/100/i))\n",
    "            i+=1\n",
    "            y_pred_best = self.model.predict(np.expand_dims(x[test][0], 0))\n",
    "            print(\"y_pred_best is: \")\n",
    "            print(y_pred_best)\n",
    "            print(y[test][0])\n",
    "            break\n",
    "        return x_feats, y_labels\n",
    "    \n",
    "\n",
    "    def train(self, x, y):\n",
    "\n",
    "        filepath = self.args.model_path\n",
    "        resultpath = self.args.result_path\n",
    "\n",
    "        if not os.path.exists(filepath):\n",
    "            os.mkdir(filepath)\n",
    "        if not os.path.exists(resultpath):\n",
    "            os.mkdir(resultpath)\n",
    "\n",
    "        i=1\n",
    "        now = datetime.datetime.now()\n",
    "        now_time = datetime.datetime.strftime(now,'%Y-%m-%d_%H-%M-%S')\n",
    "        kfold = KFold(n_splits=self.args.split_fold, shuffle=True, random_state=self.args.random_seed)\n",
    "        avg_accuracy = 0\n",
    "        avg_loss = 0\n",
    "        for train, test in kfold.split(x, y):\n",
    "            self.create_model()\n",
    "            y[train] = smooth_labels(y[train], 0.1)\n",
    "            folder_address = filepath+self.args.data+\"_\"+str(self.args.random_seed)+\"_\"+now_time\n",
    "            if not os.path.exists(folder_address):\n",
    "                os.mkdir(folder_address)\n",
    "            weight_path=folder_address+'/'+str(self.args.split_fold)+\"-fold_weights_best_\"+str(i)+\".hdf5\"\n",
    "            checkpoint = callbacks.ModelCheckpoint(weight_path, monitor='val_accuracy', verbose=1,save_weights_only=True,save_best_only=True,mode='max')\n",
    "            max_acc = 0\n",
    "            best_eva_list = []\n",
    "            h = self.model.fit(x[train], y[train],validation_data=(x[test],  y[test]),batch_size = self.args.batch_size, epochs = self.args.epoch, verbose=1,callbacks=[checkpoint])\n",
    "            self.model.load_weights(weight_path)\n",
    "            best_eva_list = self.model.evaluate(x[test],  y[test])\n",
    "            avg_loss += best_eva_list[0]\n",
    "            avg_accuracy += best_eva_list[1]\n",
    "            print(str(i)+'_Model evaluation: ', best_eva_list,\"   Now ACC:\",str(round(avg_accuracy*10000)/100/i))\n",
    "            i+=1\n",
    "            y_pred_best = self.model.predict(x[test])\n",
    "            self.matrix.append(confusion_matrix(np.argmax(y[test],axis=1),np.argmax(y_pred_best,axis=1)))\n",
    "            em = classification_report(np.argmax(y[test],axis=1),np.argmax(y_pred_best,axis=1), target_names=self.class_label,output_dict=True)\n",
    "            self.eva_matrix.append(em)\n",
    "            print(classification_report(np.argmax(y[test],axis=1),np.argmax(y_pred_best,axis=1), target_names=self.class_label))\n",
    "\n",
    "        print(\"Average ACC:\",avg_accuracy/self.args.split_fold)\n",
    "        self.acc = avg_accuracy/self.args.split_fold\n",
    "        writer = pd.ExcelWriter(resultpath+self.args.data+'_'+str(self.args.split_fold)+'fold_'+str(round(self.acc*10000)/100)+\"_\"+str(self.args.random_seed)+\"_\"+now_time+'.xlsx')\n",
    "        for i,item in enumerate(self.matrix):\n",
    "            temp = {}\n",
    "            temp[\" \"] = self.class_label\n",
    "            for j,l in enumerate(item):\n",
    "                temp[self.class_label[j]]=item[j]\n",
    "            data1 = pd.DataFrame(temp)\n",
    "            data1.to_excel(writer,sheet_name=str(i), encoding='utf8')\n",
    "\n",
    "            df = pd.DataFrame(self.eva_matrix[i]).transpose()\n",
    "            df.to_excel(writer,sheet_name=str(i)+\"_evaluate\", encoding='utf8')\n",
    "        writer.save()\n",
    "        writer.close()\n",
    "\n",
    "        K.clear_session()\n",
    "        self.matrix = []\n",
    "        self.eva_matrix = []\n",
    "        self.acc = 0\n",
    "        self.trained = True\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import soundfile as sf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_mfccs(mfccs):\n",
    "    plt.figure(figsize= (10,4))\n",
    "    librosa.display.specshow(mfccs, x_axis = \"time\" )\n",
    "    plt.colorbar(format = \"%+2.0f \")\n",
    "    plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_framed(signalpath,frame_length, skip_length):\n",
    "    y, sr = librosa.load(signalpath)\n",
    "    frame_length_samples = int(frame_length * sr)\n",
    "    skip_length_samples = int(skip_length * sr)\n",
    "\n",
    "    frames = []\n",
    "\n",
    "    for i in range(0, len(y) - frame_length_samples, skip_length_samples):\n",
    "        frame = y[i:i+frame_length_samples]\n",
    "        frames.append(frame)\n",
    "    return frames,sr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_feature_frompath(file_path = str , mfcc_len: int = 39, mean_signal_length: int = 110000):\n",
    "  \t  ## \"\"\"\n",
    "      ## file_path: Speech signal folder\n",
    "      ##mfcc_len: MFCC coefficient length\n",
    "      ##mean_signal_length: MFCC feature average length\n",
    "  \t  ##\"\"\"\n",
    "      \n",
    "    signal, fs = librosa.load(file_path)\n",
    "    s_len = len(signal)\n",
    "\n",
    "    if s_len < mean_signal_length:\n",
    "        pad_len = mean_signal_length - s_len\n",
    "        pad_rem = pad_len % 2\n",
    "        pad_len //= 2\n",
    "        signal = np.pad(signal, (pad_len, pad_len + pad_rem), 'constant', constant_values = 0)\n",
    "    else:\n",
    "        pad_len = s_len - mean_signal_length\n",
    "        pad_len //= 2\n",
    "        signal = signal[pad_len:pad_len + mean_signal_length]\n",
    "    mfcc = librosa.feature.mfcc(y=signal, sr=fs, n_mfcc=39)\n",
    "    mfcc = mfcc.T\n",
    "    feature = mfcc\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_fromsignal(signal , fs, mfcc_len: int = 39, mean_signal_length: int = 110000):\n",
    "  \t  ## \"\"\"\n",
    "      ## file_path: Speech signal folder\n",
    "      ##mfcc_len: MFCC coefficient length\n",
    "      ##mean_signal_length: MFCC feature average length\n",
    "  \t  ##\"\"\"\n",
    "      \n",
    "    s_len = len(signal)\n",
    "    \n",
    "    if s_len < mean_signal_length:\n",
    "        pad_len = mean_signal_length - s_len\n",
    "        pad_rem = pad_len % 2\n",
    "        pad_len //= 2\n",
    "        signal = np.pad(signal, (pad_len, pad_len + pad_rem), 'constant', constant_values = 0)\n",
    "    else:\n",
    "        pad_len = s_len - mean_signal_length\n",
    "        pad_len //= 2\n",
    "        signal = signal[pad_len:pad_len + mean_signal_length]\n",
    "    mfcc = librosa.feature.mfcc(y=signal, sr=fs, n_mfcc=39)\n",
    "    mfcc = mfcc.T\n",
    "    feature = mfcc\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_fromframes(signalpath,frame_length,skip_length):\n",
    "    frames, sr = get_framed(signalpath,frame_length,skip_length)\n",
    "    mfccs = [get_feature_fromsignal(frame,sr) for frame in frames]   \n",
    "    mfccs_np = np.stack(mfccs) \n",
    "    return mfccs_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_audios(audio1,audio2,combined_audio_name):\n",
    "\n",
    "    y1, sr1 = librosa.load(audio1)\n",
    "    y2, sr2 = librosa.load(audio2)\n",
    "\n",
    "    assert sr1 == sr2, \"Sample rates (sr) must be the same to concatenate the audios.\"\n",
    "\n",
    "    y = np.concatenate([y1, y2])\n",
    "    sf.write(combined_audio_name, y, sr1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multispeaker Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_speakers(audio_path, durations_file):\n",
    "    y, sr = librosa.load(audio_path)\n",
    "\n",
    "    speaker1_segments = []\n",
    "    speaker2_segments = []\n",
    "\n",
    "    with open(durations_file, 'r') as file:\n",
    "        for line in file:\n",
    "            time_range, speaker = line.strip().split(' , ')\n",
    "\n",
    "            start_time_str, end_time_str = time_range.split(' - ')\n",
    "            start_min, start_sec = map(int, start_time_str.split(':'))\n",
    "            end_min, end_sec = map(int, end_time_str.split(':'))\n",
    "\n",
    "            start_sample = ((start_min * 60) + start_sec) * sr\n",
    "            end_sample = ((end_min * 60) + end_sec) * sr\n",
    "\n",
    "            segment = y[start_sample:end_sample]\n",
    "\n",
    "            if speaker.strip() == 'speaker1':\n",
    "                speaker1_segments.append(segment)\n",
    "            else:\n",
    "                speaker2_segments.append(segment)\n",
    "\n",
    "    speaker1_audio = np.concatenate(speaker1_segments)\n",
    "    speaker2_audio = np.concatenate(speaker2_segments)\n",
    "\n",
    "    output_file_speaker1 = audio_path.split('.')[0] + '_speaker1.wav'\n",
    "    output_file_speaker2 = audio_path.split('.')[0] + '_speaker2.wav'\n",
    "\n",
    "    sf.write(output_file_speaker1, speaker1_audio, sr)\n",
    "    sf.write(output_file_speaker2, speaker2_audio, sr)\n",
    "\n",
    "    return output_file_speaker1, output_file_speaker2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(record , file):\n",
    "  \n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument('--mode', type=str, default=\"test\")\n",
    "    parser.add_argument('--model_path', type=str, default='./Models/')\n",
    "    parser.add_argument('--result_path', type=str, default='./Results/')\n",
    "    parser.add_argument('--test_path', type=str, default='./Test_Models/EMODB_46')\n",
    "    parser.add_argument('--data', type=str, default='RAVDE')\n",
    "    parser.add_argument('--lr', type=float, default=0.001)\n",
    "    parser.add_argument('--beta1', type=float, default=0.93)\n",
    "    parser.add_argument('--beta2', type=float, default=0.98)\n",
    "    parser.add_argument('--batch_size', type=int, default=64)\n",
    "    parser.add_argument('--epoch', type=int, default=60)\n",
    "    parser.add_argument('--dropout', type=float, default=0.1)\n",
    "    parser.add_argument('--random_seed', type=int, default=46)\n",
    "    parser.add_argument('--activation', type=str, default='relu')\n",
    "    parser.add_argument('--filter_size', type=int, default=39)\n",
    "    parser.add_argument('--dilation_size', type=int, default=8)# If you want to train model on IEMOCAP, you should modify this parameter to 10 due to the long duration of speech signals.\n",
    "    parser.add_argument('--kernel_size', type=int, default=2)\n",
    "    parser.add_argument('--stack_size', type=int, default=1)\n",
    "    parser.add_argument('--split_fold', type=int, default=10)\n",
    "    #parser.add_argument('--gpu', type=str, default='0')\n",
    "\n",
    "    dataset_paths = {\n",
    "        \"EMODB\": './Test_Models/EMODB_46',\n",
    "        \"CASIA\": './Test_Models/CASIA_32',\n",
    "        \"EMOVO\": './Test_Models/EMOVO_1',\n",
    "        \"IEMOCAP\" : './Test_Models/IEMOCAP_16',\n",
    "        \"RAVDE\" : './Test_Models/RAVDE_46',\n",
    "        \"SAVEE\" : './Test_Models/SAVEE_44',\n",
    "    }\n",
    "\n",
    "\n",
    "    args = parser.parse_args('--mode test --model_path ./Models/ --result_path ./Results/ --test_path ./Test_Models/RAVDE_46 --data RAVDE --lr 0.001 --beta1 0.93 --beta2 0.98 --batch_size 64 --epoch 60 --dropout 0.1 --random_seed 46 --activation relu --filter_size 39 --dilation_size 8 --kernel_size 2 --stack_size 1 --split_fold 10'.split())\n",
    "\n",
    "    if args.data==\"IEMOCAP\" and args.dilation_size!=10:\n",
    "        args.dilation_size = 10\n",
    "        print(\"IEMOCAP\")\n",
    "\n",
    "    data = np.load(\"./MFCC/\"+args.data+\".npy\",allow_pickle=True).item()\n",
    "    x_source = data[\"x\"]\n",
    "    y_source = data[\"y\"]\n",
    "\n",
    "\n",
    "    CLASS_LABELS_finetune = (\"angry\", \"fear\", \"happy\", \"neutral\",\"sad\")\n",
    "    CASIA_CLASS_LABELS = (\"angry\", \"fear\", \"happy\", \"neutral\", \"sad\", \"surprise\")#CASIA\n",
    "    EMODB_CLASS_LABELS = (\"angry\", \"boredom\", \"disgust\", \"fear\", \"happy\", \"neutral\", \"sad\")#EMODB\n",
    "    SAVEE_CLASS_LABELS = (\"angry\",\"disgust\", \"fear\", \"happy\", \"neutral\", \"sad\", \"surprise\")#SAVEE\n",
    "    RAVDE_CLASS_LABELS = (\"angry\", \"calm\", \"disgust\", \"fear\", \"happy\", \"neutral\",\"sad\",\"surprise\")#rav\n",
    "    IEMOCAP_CLASS_LABELS = (\"angry\", \"happy\", \"neutral\", \"sad\")#iemocap\n",
    "    EMOVO_CLASS_LABELS = (\"angry\", \"disgust\", \"fear\", \"happy\",\"neutral\",\"sad\",\"surprise\")#emovo\n",
    "    CLASS_LABELS_dict = {\"CASIA\": CASIA_CLASS_LABELS,\n",
    "                \"EMODB\": EMODB_CLASS_LABELS,\n",
    "                \"EMOVO\": EMOVO_CLASS_LABELS,\n",
    "                \"IEMOCAP\": IEMOCAP_CLASS_LABELS,\n",
    "                \"RAVDE\": RAVDE_CLASS_LABELS,\n",
    "                \"SAVEE\": SAVEE_CLASS_LABELS}\n",
    "    \n",
    "    CLASS_LABELS = CLASS_LABELS_dict[args.data]\n",
    "\n",
    "    model = TIMNET_Model(args=args, input_shape=x_source.shape[1:], class_label=CLASS_LABELS)\n",
    "    output_file_speaker1 , output_file_speaker2 = separate_speakers(record, file)\n",
    "    mfcc_speaker1 = get_features_fromframes(output_file_speaker1 , 5, 2)\n",
    "    mfcc_speaker2 = get_features_fromframes(output_file_speaker2 ,5 ,2)\n",
    "    model.test_two_samples(mfcc_speaker1, mfcc_speaker2)\n",
    "\n",
    "    return \n",
    "    \n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SINGLESPEAKER TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_test(record):\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument('--mode', type=str, default=\"test\")\n",
    "    parser.add_argument('--model_path', type=str, default='./Models/')\n",
    "    parser.add_argument('--result_path', type=str, default='./Results/')\n",
    "    parser.add_argument('--test_path', type=str, default='./Test_Models/EMODB_46')\n",
    "    parser.add_argument('--data', type=str, default='RAVDE')\n",
    "    parser.add_argument('--lr', type=float, default=0.001)\n",
    "    parser.add_argument('--beta1', type=float, default=0.93)\n",
    "    parser.add_argument('--beta2', type=float, default=0.98)\n",
    "    parser.add_argument('--batch_size', type=int, default=64)\n",
    "    parser.add_argument('--epoch', type=int, default=60)\n",
    "    parser.add_argument('--dropout', type=float, default=0.1)\n",
    "    parser.add_argument('--random_seed', type=int, default=46)\n",
    "    parser.add_argument('--activation', type=str, default='relu')\n",
    "    parser.add_argument('--filter_size', type=int, default=39)\n",
    "    parser.add_argument('--dilation_size', type=int, default=8)# If you want to train model on IEMOCAP, you should modify this parameter to 10 due to the long duration of speech signals.\n",
    "    parser.add_argument('--kernel_size', type=int, default=2)\n",
    "    parser.add_argument('--stack_size', type=int, default=1)\n",
    "    parser.add_argument('--split_fold', type=int, default=10)\n",
    "    #parser.add_argument('--gpu', type=str, default='0')\n",
    "\n",
    "    dataset_paths = {  \"IEMOCAP\" : './Test_Models/IEMOCAP_16',  \"RAVDE\" : './Test_Models/RAVDE_46'}\n",
    "\n",
    "    args = parser.parse_args('--mode test --model_path ./Models/ --result_path ./Results/ --test_path ./Test_Models/RAVDE_46 --data RAVDE --lr 0.001 --beta1 0.93 --beta2 0.98 --batch_size 64 --epoch 60 --dropout 0.1 --random_seed 46 --activation relu --filter_size 39 --dilation_size 8 --kernel_size 2 --stack_size 1 --split_fold 10'.split())\n",
    "\n",
    "    if args.data==\"IEMOCAP\" and args.dilation_size!=10:\n",
    "        args.dilation_size = 10\n",
    "        print(\"IEMOCAP\")\n",
    "\n",
    "    CLASS_LABELS_finetune = (\"angry\", \"fear\", \"happy\", \"neutral\",\"sad\")\n",
    "    RAVDE_CLASS_LABELS = (\"angry\", \"calm\", \"disgust\", \"fear\", \"happy\", \"neutral\",\"sad\",\"surprise\")#rav\n",
    "    IEMOCAP_CLASS_LABELS = (\"angry\", \"happy\", \"neutral\", \"sad\")#iemocap\n",
    "    CLASS_LABELS_dict = {    \"IEMOCAP\": IEMOCAP_CLASS_LABELS,   \"RAVDE\": RAVDE_CLASS_LABELS }\n",
    "\n",
    "    data = np.load(\"./MFCC/\"+args.data+\".npy\",allow_pickle=True).item()\n",
    "    x_source = data[\"x\"]\n",
    "    y_source = data[\"y\"]\n",
    "\n",
    "\n",
    "    print(\"x_source shape is: \")\n",
    "    print(x_source.shape)\n",
    "\n",
    "\n",
    "    CLASS_LABELS = CLASS_LABELS_dict[args.data]\n",
    "\n",
    "    model = TIMNET_Model(args=args, input_shape=x_source.shape[1:], class_label=CLASS_LABELS)\n",
    "    if args.mode==\"train\":\n",
    "        model.train(x_source, y_source)\n",
    "    elif args.mode==\"test\":\n",
    "        predictions = model.test_one_sample(mfccs_sof, True)\n",
    "        predictions2 = model.test_one_sample(mfccs_sof2, True)\n",
    "\n",
    "    y ,sr = librosa.load(record)\n",
    "    mfcc = get_features_fromframes(record , 5, 1)\n",
    "    predictions = model.test_one_sample(mfcc, True)\n",
    "\n",
    "    return predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
